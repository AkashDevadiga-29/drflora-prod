# -*- coding: utf-8 -*-
"""PlantModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BBljdZVBpavjT2nXbvvmJ-6llEiCyNvX

!pip install tensorflow==2.20.0 *MUST TO EXECUTE THIS CELL FIRST TO AVOID VERSION CONFLICTS*
"""

import tensorflow as tf
from keras import layers, models
import tensorflow_datasets as tfds
from keras.applications import ResNet152V2
import keras
import numpy as np
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 5

(train_raw, val_raw), info = tfds.load(
    'plant_village',
    split=['train[:80%]', 'train[80%:]'],
    with_info=True,
    as_supervised=True
)

num_classes = info.features['label'].num_classes
print(num_classes)
class_names = info.features['label'].names
print(class_names)

def format_example(image, label):
    # Resize image to the size ResNet expects
    image = tf.image.resize(image, IMG_SIZE)
    return image, label

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_raw.map(format_example, num_parallel_calls=AUTOTUNE)
train_ds = train_ds.shuffle(1000).batch(BATCH_SIZE).prefetch(AUTOTUNE)
val_ds = val_raw.map(format_example, num_parallel_calls=AUTOTUNE)
val_ds = val_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)

base_model = ResNet152V2(
    include_top=False,
    weights='imagenet',
    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)
)
base_model.trainable = True

# 2. Re-freeze everything except the last 20 layers
# ResNet152 has over 150 layers; we only want to tune the very end
for layer in base_model.layers[:-20]:
    layer.trainable = False

data_augmentation = models.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),  # Rotates up to 20% (approx 72 degrees)
    layers.RandomZoom(0.2),
    layers.RandomContrast(0.1),
])

model = models.Sequential([
    data_augmentation,
    layers.Lambda(keras.applications.resnet_v2.preprocess_input,
                  input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS
)

print("Generating predictions...")
all_labels = []
all_preds = []

# Iterate over the validation dataset
for images, labels in val_ds:
    preds = model.predict(images, verbose=0)
    # Convert probabilities to class index (e.g., [0.1, 0.8, 0.1] -> 1)
    preds = np.argmax(preds, axis=1)

    all_labels.extend(labels.numpy())
    all_preds.extend(preds)

# Create the confusion matrix
cm = confusion_matrix(all_labels, all_preds)

plt.figure(figsize=(20, 15))
sns.heatmap(cm, annot=False, fmt='d', cmap='Oranges',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix: PlantVillage ResNet152')
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.show()

import numpy as np

def predict_plant_disease(image_path):
    # 1. Load and resize the image
    img = tf.keras.utils.load_img(image_path, target_size=(224, 224))

    # 2. Convert to a numpy array
    img_array = tf.keras.utils.img_to_array(img)

    # 3. Add the Batch Dimension (1, 224, 224, 3)
    img_array = np.expand_dims(img_array, axis=0)

    # 5. Predict!
    predictions = model.predict(img_array)

    # 6. Get the result (REMOVED: tf.nn.softmax)
    # Your model already outputs softmax probabilities. Softmaxing a
    # second time flattens the confidence scores.
    class_idx = np.argmax(predictions[0])
    confidence = 100 * predictions[0][class_idx]

    print(f"Predicted: {class_names[class_idx]}")
    print(f"Confidence: {confidence:.2f}%")

# Call the function with your Grape image
predict_plant_disease('/content/image (8).JPG')

model.save("plantmodel.keras")
print("Model saved!!!")
!cp plantmodel.keras /content/drive/MyDrive/
print("Model backed up to Google Drive!")